{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee0194c",
   "metadata": {},
   "source": [
    "# 계산기 에이전트 만들기\n",
    "\n",
    "이 예제에서는 **LangGraph의 Graph API** 또는 **Functional API** 를 사용하여\n",
    "**계산기 에이전트(calculator agent)** 를 만드는 방법을 보여줍니다.\n",
    "\n",
    "* **Graph API**\n",
    "  에이전트를 **노드(node)** 와 **엣지(edge)** 로 구성된 **그래프 형태**로 정의하고 싶을 때 사용합니다.\n",
    "  (즉, 여러 처리 단계를 시각적으로 구성하고 싶은 경우)\n",
    "\n",
    "* **Functional API**\n",
    "  에이전트를 **하나의 함수(function)** 로 정의하고 싶을 때 사용합니다.\n",
    "  (즉, 단일 입력 → 단일 출력 구조를 선호하는 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b1569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9266825b-2c57-46e8-9bf2-d7c939623137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633786c9-e90e-43b1-a426-04451bba281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000016DE46FB380>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': '`a`와 `b`를 더합니다.\\n\\n매개변수(Args):\\n    a: 첫 번째 정수\\n    b: 두 번째 정수', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': '`a`와 `b`를 곱합니다.\\n\\n매개변수(Args):\\n    a: 첫 번째 정수\\n    b: 두 번째 정수', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'divide', 'description': '`a`를 `b`로 나눕니다.\\n\\n매개변수(Args):\\n    a: 첫 번째 정수\\n    b: 두 번째 정수', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# 도구 정의 (LLM이 사용할 수 있는 계산 기능)\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"`a`와 `b`를 곱합니다.\n",
    "\n",
    "    매개변수(Args):\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"`a`와 `b`를 더합니다.\n",
    "\n",
    "    매개변수(Args):\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"`a`를 `b`로 나눕니다.\n",
    "\n",
    "    매개변수(Args):\n",
    "        a: 첫 번째 정수\n",
    "        b: 두 번째 정수\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "# 사용할 도구(연산 함수)들을 리스트로 정의\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# 도구 이름(name)을 키로 하여 빠르게 접근할 수 있는 딕셔너리 형태로 변환\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# 모델에 도구 목록을 바인딩(bind)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "model_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e2990-fbea-4b96-bf89-60e3b0039d8c",
   "metadata": {},
   "source": [
    "### **모델 노드(Model Node) 정의**\n",
    "\n",
    "모델 노드는 **LLM(대형 언어 모델)** 을 호출하고, **도구(tool)** 를 호출해야 할지 여부를 결정하는 역할을 합니다.  \n",
    "즉, 이 노드는 모델이 입력된 메시지를 바탕으로\n",
    "“직접 대답할지” 혹은 “도구(예: 계산기, 검색기 등)를 사용해야 할지” 판단하는 **의사결정 지점**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d49415-c445-4097-b42b-f293125f6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage, ToolCall\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.func import entrypoint, task\n",
    "\n",
    "@task\n",
    "def call_llm(messages: list[BaseMessage]):\n",
    "    \"\"\"LLM이 도구를 호출할지 여부를 결정합니다.\"\"\"\n",
    "    return model_with_tools.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"당신은 주어진 입력값에 대해 산술 연산을 수행하는 친절한 도우미입니다.\"\n",
    "            )\n",
    "        ]\n",
    "        + messages  # 이전 대화 메시지를 함께 전달\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23699ae2-9bc3-4685-bb04-4f9ff3cc51ba",
   "metadata": {},
   "source": [
    "### **도구 노드 정의 (Define tool node)**\n",
    "\n",
    "도구 노드는 **등록된 도구(tools)** 를 실제로 호출하고, 그 **결과(result)** 를 반환하는 역할을 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a73f913-1949-4345-a12f-7863b5026bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def call_tool(tool_call: ToolCall):\n",
    "    \"\"\"도구 호출을 수행합니다.\"\"\"\n",
    "    tool = tools_by_name[tool_call[\"name\"]]  # 호출된 도구 이름에 해당하는 실제 도구 객체를 가져옴\n",
    "    return tool.invoke(tool_call)            # 해당 도구를 실행하고 결과를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b24559-23f4-4a30-823d-04a97d3a6bdd",
   "metadata": {},
   "source": [
    "### **에이전트 정의**\n",
    "`@entrypoint`는 **LangGraph Functional API**에서 에이전트의 **시작점(진입 지점, entry point)** 을 정의하는 데 사용됩니다.\n",
    "\n",
    "이 함수 안에서는 LLM 호출, 도구 실행, 조건 분기 등 에이전트의 전체 동작 흐름을 **일반적인 파이썬 제어 구조(루프, 조건문 등)** 로 구성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c400d5b6-20d2-4365-a00c-b9cafbb48dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call_llm': AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 3, \"b\": 4}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--300dd601-9fef-4d0d-bc44-4479fb320d4f-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': '3d43b45a-d400-49c1-80fc-243fd5d74c78', 'type': 'tool_call'}], usage_metadata={'input_tokens': 264, 'output_tokens': 80, 'total_tokens': 344, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 62}})}\n",
      "\n",
      "\n",
      "{'call_tool': ToolMessage(content='7', name='add', tool_call_id='3d43b45a-d400-49c1-80fc-243fd5d74c78')}\n",
      "\n",
      "\n",
      "{'call_llm': AIMessage(content='3과 4를 더한 결과는 7입니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--9e6e5a11-b6bf-495d-bc95-2493eebb8bdd-0', usage_metadata={'input_tokens': 295, 'output_tokens': 13, 'total_tokens': 308, 'input_token_details': {'cache_read': 0}})}\n",
      "\n",
      "\n",
      "{'agent': [HumanMessage(content='3과 4를 더해줘.', additional_kwargs={}, response_metadata={}, id='bfe9fde0-99ae-45de-b019-4bdb32cb2ec5'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 3, \"b\": 4}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--300dd601-9fef-4d0d-bc44-4479fb320d4f-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 4}, 'id': '3d43b45a-d400-49c1-80fc-243fd5d74c78', 'type': 'tool_call'}], usage_metadata={'input_tokens': 264, 'output_tokens': 80, 'total_tokens': 344, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 62}}), ToolMessage(content='7', name='add', id='00ddfcfd-29b9-416b-8382-02aead0d244d', tool_call_id='3d43b45a-d400-49c1-80fc-243fd5d74c78'), AIMessage(content='3과 4를 더한 결과는 7입니다.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--9e6e5a11-b6bf-495d-bc95-2493eebb8bdd-0', usage_metadata={'input_tokens': 295, 'output_tokens': 13, 'total_tokens': 308, 'input_token_details': {'cache_read': 0}})]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import add_messages\n",
    "\n",
    "@entrypoint()\n",
    "def agent(messages: list[BaseMessage]):\n",
    "    model_response = call_llm(messages).result()\n",
    "\n",
    "    while True:\n",
    "        if not model_response.tool_calls:\n",
    "            break\n",
    "\n",
    "        # 도구 실행\n",
    "        tool_result_futures = [\n",
    "            call_tool(tool_call) for tool_call in model_response.tool_calls\n",
    "        ]\n",
    "        tool_results = [fut.result() for fut in tool_result_futures]\n",
    "        messages = add_messages(messages, [model_response, *tool_results])\n",
    "        model_response = call_llm(messages).result()\n",
    "\n",
    "    messages = add_messages(messages, model_response)\n",
    "    return messages\n",
    "\n",
    "# 에이전트 실행\n",
    "messages = [HumanMessage(content=\"3과 4를 더해줘.\")]\n",
    "for chunk in agent.stream(messages, stream_mode=\"updates\"):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db555a5a-cb16-4c34-9d9e-64c0e6a100ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
