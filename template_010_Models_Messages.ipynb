{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {
    "editable": true,
    "id": "9316da0d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **챗 모델과 Message를 사용해 간단한 LLM 애플리케이션 구축하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521af64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {
    "id": "e5558ca9"
   },
   "source": [
    "## 언어 모델 사용하기\n",
    "\n",
    "LangChain은 다양한 언어 모델을 지원하며, 이들을 서로 교체하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c566e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {
    "id": "ca5642ff"
   },
   "source": [
    "ChatModels은 LangChain Runnables의 인스턴스로, 표준화된 인터페이스를 통해 상호작용할 수 있습니다. 모델을 간단히 호출하려면 `.invoke` 메서드에 Messages 목록을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc68f2-e940-41af-b949-9bec65100923",
   "metadata": {},
   "source": [
    "## 메시지 (Messages)\n",
    "\n",
    "메시지(Messages) 는 LangChain에서 모델이 사용하는 컨텍스트의 기본 단위입니다.\n",
    "이들은 모델의 입력(input) 과 출력(output) 을 나타내며, LLM과의 상호작용에서 대화의 상태(state)를 표현하는 데 필요한 콘텐츠(content) 와 메타데이터(metadata) 를 함께 포함합니다.\n",
    "\n",
    "메시지는 다음 요소들로 구성됩니다:\n",
    "\n",
    "- Role (역할)\n",
    "→ 메시지의 유형을 식별합니다. 예: system, user, assistant 등  \n",
    "- Content (내용)\n",
    "→ 메시지의 실제 내용으로, 텍스트뿐만 아니라 이미지, 오디오, 문서 등 다양한 형식을 포함할 수 있습니다.  \n",
    "- Metadata (메타데이터)\n",
    "→ 선택적(optional) 필드로, 응답 정보(response info), 메시지 ID, 토큰 사용량(token usage) 등 부가 정보를 담습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 목록을 생성\n",
    "    # 시스템 메시지: 모델에게 수행할 작업이나 역할을 지시합니다.\n",
    "    # 사용자 메시지: 사용자가 모델에 보낼 실제 입력 내용입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19b7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95cbd960-d92a-42ba-89c5-a4a664bc7b88",
   "metadata": {},
   "source": [
    "### 텍스트 프롬프트 (Text prompts)\n",
    "\n",
    "**텍스트 프롬프트(Text prompts)** 는 단순한 **문자열(string)** 형태로 제공됩니다.  \n",
    "대화 기록(conversation history)을 유지할 필요가 없는 **단순한 생성 작업**(예: 요약, 문장 생성, 번역 등)에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3e08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85ae698-b258-41f2-bff3-591e871781ae",
   "metadata": {},
   "source": [
    "### 딕셔너리 형식 (Dictionary format)\n",
    "\n",
    "OpenAI의 **Chat Completions 포맷**을 사용해 메시지를 **딕셔너리 형태로 직접 지정**할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e119760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 형식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101b1e5-00e3-44cd-99e8-622c9076964f",
   "metadata": {},
   "source": [
    "--------------\n",
    "## 메시지 유형 (Message types)\n",
    "\n",
    "* **System message (시스템 메시지)**\n",
    "  → 모델이 어떻게 행동해야 하는지 지시하고, 상호작용의 **맥락(context)** 을 제공합니다.  \n",
    "* **Human message (사용자 메시지)**\n",
    "  → 사용자의 입력을 나타내며, 모델과의 **대화(interaction)** 를 구성합니다.  \n",
    "* **AI message (AI 메시지)**\n",
    "  → 모델이 생성한 응답으로, **텍스트 내용(text content)** 뿐 아니라\n",
    "  **도구 호출(tool calls)** 및 **메타데이터(metadata)** 를 포함할 수 있습니다.  \n",
    "* **Tool message (도구 메시지)**\n",
    "  → 모델이 호출한 **도구의 실행 결과(outputs)** 를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ece94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afd416a6-4bb9-4c1d-a43a-d52c5f8a4b5d",
   "metadata": {},
   "source": [
    "### AI 메시지 (AI Message)\n",
    "\n",
    "**AIMessage** 는 **모델 호출(model invocation)** 의 **출력 결과**를 나타냅니다.\n",
    "이 메시지에는 다음과 같은 요소들을 포함할 수 있습니다:\n",
    "\n",
    "* **멀티모달 데이터 (Multimodal data)** — 텍스트뿐만 아니라 이미지, 오디오 등의 출력\n",
    "* **도구 호출 (Tool calls)** — 모델이 외부 도구를 실행한 기록\n",
    "* **제공자별 메타데이터 (Provider-specific metadata)** — 모델 제공자(OpenAI, Anthropic 등)에 따라 추가로 제공되는 정보\n",
    "\n",
    "이러한 메타데이터는 나중에 접근하거나 분석할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 메시지를 수동으로 생성 (예: 대화 기록에 추가하기 위해)\n",
    "# 대화 기록에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a4174-9202-43d4-b458-55c5f67463ed",
   "metadata": {},
   "source": [
    "### 토큰 사용량 (Token usage)\n",
    "\n",
    "**AIMessage** 객체는 `usage_metadata` 필드에\n",
    "**토큰 사용량(token counts)** 및 기타 **사용 관련 메타데이터(metadata)** 를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2230cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ecf8e88-819c-445f-ae28-92f05e549cb4",
   "metadata": {},
   "source": [
    "### batch interface 이용 여러개의 메시지 일괄 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a763c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 목록을 생성\n",
    "# `model.batch()`을 사용하여 여러 개의 메시지를 한 번에 처리\n",
    "# LangChain은 각 입력을 독립된 invoke() 호출처럼 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d335ec-dcc9-4b4e-a714-74ab509d71cd",
   "metadata": {},
   "source": [
    "### stream inferface 를 이용한 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f15771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 중에 받아온 chunk 들을 저장할 리스트\n",
    "# 전체 메시지를 누적할 변수\n",
    "# model.stream() 은 토큰(혹은 chunk)을 스트리밍 방식으로 하나씩 생성\n",
    "    # full_message 에 chunk 를 누적\n",
    "    # 첫 chunk 일 경우 full_message 가 None 이므로 그대로 저장\n",
    "    # 이후부터는 기존 full_message 에 chunk 를 더해(concat) 전체 메시지를 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d365601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ad55ad5-505f-4ff7-bbd9-d406c86eea55",
   "metadata": {},
   "source": [
    "### 도구 메시지 (Tool Message)\n",
    "\n",
    "도구 호출(tool calling)을 지원하는 모델의 경우,\n",
    "**AI 메시지(AIMessage)** 안에 **도구 호출 정보(tool calls)** 가 포함될 수 있습니다.\n",
    "\n",
    "**Tool Message(도구 메시지)** 는\n",
    "**단일 도구 실행의 결과(result)** 를 모델에게 다시 전달하기 위해 사용됩니다.\n",
    "\n",
    "또한, 도구는 직접 **`ToolMessage` 객체**를 생성하여\n",
    "실행 결과를 LangChain 에이전트나 모델로 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 도구 호출을 수행한 후\n",
    "# 도구 실행 후 결과 메시지 생성\n",
    "# 대화 이어가기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488283a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
