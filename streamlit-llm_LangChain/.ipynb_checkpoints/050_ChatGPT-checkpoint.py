#---------------------------------------------------------
# langgraphë¥¼ ì´ìš©í•œ Chatbot êµ¬í˜„
#---------------------------------------------------------
# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())

import streamlit as st
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, MessagesState
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# streamlit_chat ë¼ì´ë¸ŒëŸ¬ë¦¬
from streamlit_chat import message  # ì±„íŒ… ë§í’ì„  í˜•íƒœë¡œ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4.1-nano")

# ---------------------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------------------------------
# ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í˜ì´ì§€ ì œëª©ê³¼ ì•„ì´ì½˜ì„ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ ChatGPT", page_icon=":robot_face:")

# í˜ì´ì§€ ì œëª©ì„ ì¤‘ì•™ì— ì •ë ¬í•˜ì—¬ í‘œì‹œ
# - unsafe_allow_html=True: HTMLì„ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©
st.markdown("<h1 style='text-align: center;'>ìš°ë¦¬ ì¦ê²ê²Œ ëŒ€í™”í•´ìš”</h1>", unsafe_allow_html=True)

# ---------------------------------------------------------------------------------
# ì‚¬ì´ë“œë°” ë²„íŠ¼ ì„¤ì •
# ---------------------------------------------------------------------------------
st.sidebar.title("ğŸ˜")
refresh_button = st.sidebar.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”")
summaries_button = st.sidebar.button("ëŒ€í™” ë‚´ìš© ìš”ì•½")

# ---------------------------------------------------------------------------------
# LangGraph ì•±ê³¼ MemorySaver ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒë§Œ)
# ---------------------------------------------------------------------------------
if "app" not in st.session_state:
    
    # 1) LangGraphì˜ ì›Œí¬í”Œë¡œìš°(StateGraph) ì •ì˜
    workflow = StateGraph(state_schema=MessagesState)

    # 1-1) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (í‘œì¤€ êµ¬ì¡° ì ìš©)
    prompt_template = ChatPromptTemplate.from_messages([
        ("system", "ë‹¹ì‹ ì€ ì¹œêµ¬ì²˜ëŸ¼ ë§í•©ë‹ˆë‹¤. ëª¨ë“  ì§ˆë¬¸ì— ìµœì„ ì„ ë‹¤í•´ ëŒ€ë‹µí•˜ì„¸ìš”."),
        MessagesPlaceholder(variable_name="messages"),
    ])

    # 2) ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ ì •ì˜ (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©)
    def call_model(state: MessagesState):
        prompt = prompt_template.invoke({"messages": state["messages"]})
        response = llm.invoke(prompt)
        return {"messages": response}

    # 3) ë…¸ë“œ ë° ì—£ì§€ ì—°ê²°
    workflow.add_node("model", call_model)
    workflow.add_edge(START, "model")

    # 4) MemorySaverë¥¼ ì‚¬ìš©í•´ ëŒ€í™” ìƒíƒœë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°
    memory = MemorySaver()

    # 5) LangGraph ì•± ì»´íŒŒì¼
    st.session_state.app = workflow.compile(checkpointer=memory)

    # 6) ëŒ€í™” ì´ë ¥ì„ ì €ì¥í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    st.session_state.messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ìœ ìš©í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.")
    ]

# ---------------------------------------------------------------------------------
# ì‚¬ì´ë“œë°” ë²„íŠ¼ ë™ì‘ ì •ì˜
# ---------------------------------------------------------------------------------
# 1) "ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”" ë²„íŠ¼: ëŒ€í™” ê¸°ë¡ ë¦¬ì…‹
if refresh_button:
    st.session_state.messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ìœ ìš©í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.")
    ]

# 2) "ëŒ€í™” ë‚´ìš© ìš”ì•½" ë²„íŠ¼: LLMì—ê²Œ ìš”ì•½ì„ ìš”ì²­í•´ ê²°ê³¼ë¥¼ ì‚¬ì´ë“œë°”ì— í‘œì‹œ
if summaries_button:
    
    # 2-1) ë©”ì‹œì§€ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
    conversation_text = []
    for msg in st.session_state.messages:
        if isinstance(msg, SystemMessage):
            role = "System"
        elif isinstance(msg, HumanMessage):
            role = "User"
        elif isinstance(msg, AIMessage):
            role = "AI"
        else:
            role = "Unknown"
        conversation_text.append(f"{role}: {msg.content}")
        
    joined_conversation = "\n".join(conversation_text)

    # 2-2) ìš”ì•½ í”„ë¡¬í”„íŠ¸ ë§Œë“¤ê¸°
    prompt_content = f"""ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:
            {joined_conversation}
            --- 
            ìš”ì•½:
            """

    # 2-3) LLMì—ê²Œ ìš”ì•½ ìš”ì²­
    summary_response = llm.invoke([HumanMessage(content=prompt_content)])
    summary_text = summary_response.content

    # 2-4) ì‚¬ì´ë“œë°”ì— ìš”ì•½ ê²°ê³¼ í‘œì‹œ
    st.sidebar.write("**ëŒ€í™” ìš”ì•½:**")
    st.sidebar.write(summary_text)

# ---------------------------------------------------------------------------------
# ë©”ì¸ ì˜ì—­: ì…ë ¥ í¼ ë° ëª¨ë¸ í˜¸ì¶œ
# clear_on_submit=True : í¼ì´ ì œì¶œë  ë•Œ ì…ë ¥ í•„ë“œ ìë™ ì´ˆê¸°í™”
# ---------------------------------------------------------------------------------
with st.form(key='my_form', clear_on_submit=True):
    user_input = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", key='input', height=100)
    submit_button = st.form_submit_button(label='Send')

    if submit_button and user_input:
        # ì‚¬ìš©ì ì…ë ¥ì„ HumanMessage ë¡œ ì¶”ê°€
        st.session_state.messages.append(HumanMessage(content=user_input))
        
        # LangGraph ì•±ì„ í˜¸ì¶œí•´ AI ì‘ë‹µ ìƒì„±
        output = st.session_state.app.invoke(
            {"messages": user_input},
            config={"configurable": {"thread_id": "chat1"}}
        )
        
        # ìƒˆë¡­ê²Œ ìƒì„±ëœ AI ì‘ë‹µ
        response = output["messages"][-1].content
        st.session_state.messages.append(AIMessage(content=response))

# ---------------------------------------------------------------------------------
# "ë§ˆì§€ë§‰ AIMessage" í¼ ë°”ë¡œ ì•„ë˜ì— í‘œì‹œ
# ---------------------------------------------------------------------------------
# - ëŒ€í™” ì´ë ¥ì´ ë¹„ì–´ìˆì§€ ì•Šê³ , ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ AIMessageì´ë©´ í‘œì‹œ
if st.session_state.messages:
    last_msg = st.session_state.messages[-1]
    if isinstance(last_msg, AIMessage):
        st.text(last_msg.content)

# ---------------------------------------------------------------------------------
# ê·¸ ì™¸ì˜ ëŒ€í™” ì´ë ¥(ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì œì™¸)ì„ ì•„ë˜ì—ì„œ ìˆœì„œëŒ€ë¡œ í‘œì‹œ
# is_user=True : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì„¸ì§€
# ---------------------------------------------------------------------------------
st.subheader("ì´ì „ ëŒ€í™” ì´ë ¥")
for idx, msg in enumerate(st.session_state.messages):  # ë§¨ ë§ˆì§€ë§‰ AIMessageëŠ” ì œì™¸
    if isinstance(msg, HumanMessage):
        message(msg.content, is_user=True, key=str(idx) + "_user")
    elif isinstance(msg, AIMessage):
        message(msg.content, is_user=False, key=str(idx) + "_ai")
