{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {
    "editable": true,
    "id": "9316da0d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **챗 모델과 Message를 사용해 간단한 LLM 애플리케이션 구축하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "I1APsrLauEiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1APsrLauEiT",
    "outputId": "07352eb4-b720-42c9-cc5d-7778166cb1fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e1b785-ee30-49d7-8b75-a6f75d26c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {
    "id": "e5558ca9"
   },
   "source": [
    "## 언어 모델 사용하기\n",
    "\n",
    "LangChain은 다양한 언어 모델을 지원하며, 이들을 서로 교체하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b41234",
   "metadata": {
    "id": "e4b41234"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {
    "id": "ca5642ff"
   },
   "source": [
    "ChatModels은 LangChain Runnables의 인스턴스로, 표준화된 인터페이스를 통해 상호작용할 수 있습니다. 모델을 간단히 호출하려면 `.invoke` 메서드에 Messages 목록을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc68f2-e940-41af-b949-9bec65100923",
   "metadata": {},
   "source": [
    "## 메시지 (Messages)\n",
    "\n",
    "메시지(Messages) 는 LangChain에서 모델이 사용하는 컨텍스트의 기본 단위입니다.\n",
    "이들은 모델의 입력(input) 과 출력(output) 을 나타내며, LLM과의 상호작용에서 대화의 상태(state)를 표현하는 데 필요한 콘텐츠(content) 와 메타데이터(metadata) 를 함께 포함합니다.\n",
    "\n",
    "메시지는 다음 요소들로 구성됩니다:\n",
    "\n",
    "- Role (역할)\n",
    "→ 메시지의 유형을 식별합니다. 예: system, user, assistant 등  \n",
    "- Content (내용)\n",
    "→ 메시지의 실제 내용으로, 텍스트뿐만 아니라 이미지, 오디오, 문서 등 다양한 형식을 포함할 수 있습니다.  \n",
    "- Metadata (메타데이터)\n",
    "→ 선택적(optional) 필드로, 응답 정보(response info), 메시지 ID, 토큰 사용량(token usage) 등 부가 정보를 담습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2481f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b2481f0",
    "outputId": "4323da7b-9ebf-4ed3-f3b1-5cf182dafd16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain이란 무엇입니까?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 40, 'total_tokens': 249, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ce9015uzb1k3oxcNZFBfArL2maLX0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--6e06e98c-2af9-4a3d-a8a3-5f0d5721ebea-0', usage_metadata={'input_tokens': 40, 'output_tokens': 209, 'total_tokens': 249, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 메시지 목록을 생성\n",
    "messages = [\n",
    "    # 시스템 메시지: 모델에게 수행할 작업이나 역할을 지시합니다.\n",
    "    SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "    # 사용자 메시지: 사용자가 모델에 보낼 실제 입력 내용입니다.\n",
    "    HumanMessage(\"What is LangChain?\"),\n",
    "]\n",
    "\n",
    "answer = model.invoke(messages)  # `invoke` 메서드를 사용해 모델을 호출합니다.\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "CGRBL2IrZcsP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGRBL2IrZcsP",
    "outputId": "2d3464d8-e61c-4972-a3d2-c3de59493a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain이란 무엇입니까?\n"
     ]
    }
   ],
   "source": [
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cbd960-d92a-42ba-89c5-a4a664bc7b88",
   "metadata": {},
   "source": [
    "### 텍스트 프롬프트 (Text prompts)\n",
    "\n",
    "**텍스트 프롬프트(Text prompts)** 는 단순한 **문자열(string)** 형태로 제공됩니다.  \n",
    "대화 기록(conversation history)을 유지할 필요가 없는 **단순한 생성 작업**(예: 요약, 문장 생성, 번역 등)에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1034d669-aa6e-4980-9ada-c4f97e63e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "토큰의 바다를 헤엄치는 LLM, 말의 심장을 울린다.\n",
      "질문은 은빛 파도, 맥락은 그 위를 잇는 다리.\n",
      "수정된 문장이 모여 이야기를 펼치고, 지식은 별처럼 빛난다.\n",
      "우리는 물음과 답의 대화를 통해 서로의 상상을 넓힌다.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"LLM 에 관한 시를 5줄 이내로 지어주세요.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ae698-b258-41f2-bff3-591e871781ae",
   "metadata": {},
   "source": [
    "### 딕셔너리 형식 (Dictionary format)\n",
    "\n",
    "OpenAI의 **Chat Completions 포맷**을 사용해 메시지를 **딕셔너리 형태로 직접 지정**할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b65209b-6307-414f-a612-d8cfa114e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain이란 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 형식\n",
    "answer = model.invoke([\n",
    "    {\"role\": \"system\", \"content\": \"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is LangChain?\"},\n",
    "])\n",
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101b1e5-00e3-44cd-99e8-622c9076964f",
   "metadata": {},
   "source": [
    "--------------\n",
    "## 메시지 유형 (Message types)\n",
    "\n",
    "* **System message (시스템 메시지)**\n",
    "  → 모델이 어떻게 행동해야 하는지 지시하고, 상호작용의 **맥락(context)** 을 제공합니다.  \n",
    "* **Human message (사용자 메시지)**\n",
    "  → 사용자의 입력을 나타내며, 모델과의 **대화(interaction)** 를 구성합니다.  \n",
    "* **AI message (AI 메시지)**\n",
    "  → 모델이 생성한 응답으로, **텍스트 내용(text content)** 뿐 아니라\n",
    "  **도구 호출(tool calls)** 및 **메타데이터(metadata)** 를 포함할 수 있습니다.  \n",
    "* **Tool message (도구 메시지)**\n",
    "  → 모델이 호출한 **도구의 실행 결과(outputs)** 를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b244e713-c236-43e7-b2d6-efa2b9764527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- 프레임워크 선택: FastAPI(현대적이고 문서화 자동) 또는 Django REST Framework 등.\n",
      "- 모델/리소스 정의와 RESTful 엔드포인트 설계: 예를 들어 /items, /items/{id}를 GET/POST/PUT/PATCH/DELETE로 매핑.\n",
      "- 직렬화 및 유효성 검증: FastAPI의 Pydantic 또는 DRF Serializer 활용.\n",
      "- DB 연결/비즈니스 로직: ORM으로 모델링, 마이그레이션, 인증(JWT 등) 추가.\n",
      "- 테스트와 배포: 자동 문서(OpenAPI/Swagger), Uvicorn/Gunicorn 같은 서버로 배포 및 모니터링.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "당신은 웹 프레임워크에 전문성을 가진 시니어 Python 개발자입니다.\n",
    "설명은 간결하게 5줄 이내로 설명하세요.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"REST API를 어떻게 만들 수 있나요?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd416a6-4bb9-4c1d-a43a-d52c5f8a4b5d",
   "metadata": {},
   "source": [
    "### AI 메시지 (AI Message)\n",
    "\n",
    "**AIMessage** 는 **모델 호출(model invocation)** 의 **출력 결과**를 나타냅니다.\n",
    "이 메시지에는 다음과 같은 요소들을 포함할 수 있습니다:\n",
    "\n",
    "* **멀티모달 데이터 (Multimodal data)** — 텍스트뿐만 아니라 이미지, 오디오 등의 출력\n",
    "* **도구 호출 (Tool calls)** — 모델이 외부 도구를 실행한 기록\n",
    "* **제공자별 메타데이터 (Provider-specific metadata)** — 모델 제공자(OpenAI, Anthropic 등)에 따라 추가로 제공되는 정보\n",
    "\n",
    "이러한 메타데이터는 나중에 접근하거나 분석할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45de4fe-764a-4da1-90bf-c5ecf06da539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI(인공지능)은 데이터를 기반으로 학습하고 패턴을 인식해 인간처럼 문제를 해결하거나 의사결정을 도와주는 컴퓨터 시스템의 능력이다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 304, 'prompt_tokens': 16, 'total_tokens': 320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ce90vt3zmAN0NrZU8ThMH4WDPK1wj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9ba1a778-314d-4ebd-bdcc-e8234dcb62eb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 304, 'total_tokens': 320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"AI에 대해서 한줄로 설명해줘.\")\n",
    "print(type(response))  \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb097b8e-c693-4957-a33f-db56b6b995ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 + 2 = 4 입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# AI 메시지를 수동으로 생성 (예: 대화 기록에 추가하기 위해)\n",
    "ai_msg = AIMessage(\"그 질문에 기꺼이 도움을 드리겠습니다!\")\n",
    "\n",
    "# 대화 기록에 추가\n",
    "messages = [\n",
    "    SystemMessage(\"당신은 도움이 되는 어시스턴트입니다.\"),\n",
    "    HumanMessage(\"저를 도와주실 수 있나요?\"),\n",
    "    ai_msg,  # 모델이 이전에 응답한 것처럼 삽입\n",
    "    HumanMessage(\"좋아요! 그럼 2 + 2는 얼마인가요?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a4174-9202-43d4-b458-55c5f67463ed",
   "metadata": {},
   "source": [
    "### 토큰 사용량 (Token usage)\n",
    "\n",
    "**AIMessage** 객체는 `usage_metadata` 필드에\n",
    "**토큰 사용량(token counts)** 및 기타 **사용 관련 메타데이터(metadata)** 를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed023e1c-0c69-42d8-99d9-2fb0ab1ade9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 8,\n",
       " 'output_tokens': 355,\n",
       " 'total_tokens': 363,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 256}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Hello!\")\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf8e88-819c-445f-ae28-92f05e549cb4",
   "metadata": {},
   "source": [
    "### batch interface 이용 여러개의 메시지 일괄 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f26b9c15-aefd-4908-a3c8-0d558f39b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='LangChain이 무엇인가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 208, 'prompt_tokens': 40, 'total_tokens': 248, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ce9AtIdhbfiIjAaV54GZhdAc6SwfF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--996cfa1a-7b37-4ef2-9734-8025c9c43cd4-0', usage_metadata={'input_tokens': 40, 'output_tokens': 208, 'total_tokens': 248, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}),\n",
       " AIMessage(content='LangChain은 어떻게 작동합니까?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 274, 'prompt_tokens': 41, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ce9AtaX81ZFE4Y4NfMpkYibrvOO7M', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a8c93e4c-8864-4f19-8a47-c343a775ce8b-0', usage_metadata={'input_tokens': 41, 'output_tokens': 274, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}),\n",
       " AIMessage(content='LangChain의 주요 특징은 무엇입니까?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 44, 'total_tokens': 319, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Ce9AuD0kTyn1UWLhK81TwVjEKpNhc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--54e02cb4-eafa-41f4-b87e-a2d0ca6d2938-0', usage_metadata={'input_tokens': 44, 'output_tokens': 275, 'total_tokens': 319, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메시지 목록을 생성\n",
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What is LangChain?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"How does LangChain work?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What are the key features of LangChain?\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "# `model.batch()`을 사용하여 여러 개의 메시지를 한 번에 처리\n",
    "# LangChain은 각 입력을 독립된 invoke() 호출처럼 처리\n",
    "answers = model.batch(batch_messages)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "018da27f-d225-4f9d-aa94-6d6cabce66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 1: LangChain이 무엇인가요?\n",
      "번역 2: LangChain은 어떻게 작동합니까?\n",
      "번역 3: LangChain의 주요 특징은 무엇입니까?\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for idx, ans in enumerate(answers):\n",
    "    print(f\"번역 {idx + 1}: {ans.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d335ec-dcc9-4b4e-a714-74ab509d71cd",
   "metadata": {},
   "source": [
    "### stream inferface 를 이용한 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c76047bf-3c63-4460-9f5d-f991aa6472a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "여\n",
      "러\n",
      " 가지\n",
      " L\n",
      "LM\n",
      " 기반\n",
      " 애\n",
      "플\n",
      "리\n",
      "케\n",
      "이션\n",
      "을\n",
      " 쉽게\n",
      " 구축\n",
      "하도록\n",
      " 돕\n",
      "는\n",
      " 프\n",
      "레\n",
      "임\n",
      "워크\n",
      "가\n",
      " Lang\n",
      "Chain\n",
      "입니다\n",
      ".\n",
      " 주요\n",
      " 기능\n",
      "을\n",
      " 요\n",
      "약\n",
      "하면\n",
      " 다음\n",
      "과\n",
      " 같습니다\n",
      ".\n",
      "\n",
      "\n",
      "-\n",
      " L\n",
      "LM\n",
      " 및\n",
      " 프\n",
      "롬\n",
      "프트\n",
      " 관리\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 다양한\n",
      " L\n",
      "LM\n",
      " 공급\n",
      "자\n",
      "와\n",
      "의\n",
      " 래\n",
      "퍼\n",
      " 지원\n",
      "(Open\n",
      "AI\n",
      ",\n",
      " Coh\n",
      "ere\n",
      ",\n",
      " Hug\n",
      "ging\n",
      "Face\n",
      " 등\n",
      ")\n",
      "\n",
      " \n",
      " -\n",
      " Prompt\n",
      "Template\n",
      ",\n",
      " Chat\n",
      "Prompt\n",
      "Template\n",
      " 등을\n",
      " 이용\n",
      "한\n",
      " 재\n",
      "사용\n",
      " 가능한\n",
      " 프\n",
      "롬\n",
      "프트\n",
      " 구성\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 체\n",
      "인\n",
      "(\n",
      "Chain\n",
      ")\n",
      " 기반\n",
      " 파\n",
      "이\n",
      "프\n",
      "라인\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " L\n",
      "LM\n",
      "Chain\n",
      ",\n",
      " Simple\n",
      "Sequential\n",
      "Chain\n",
      ",\n",
      " Sequential\n",
      "Chain\n",
      " 등\n",
      "으로\n",
      " 여러\n",
      " L\n",
      "LM\n",
      " 호출\n",
      "을\n",
      " 순\n",
      "차\n",
      "적으로\n",
      " 연결\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 파\n",
      "이\n",
      "프\n",
      "라인\n",
      " 형태\n",
      "의\n",
      " 로\n",
      "직\n",
      "을\n",
      " 손\n",
      "쉽\n",
      "게\n",
      " 구성\n",
      "하고\n",
      " 재\n",
      "사용\n",
      " 가능\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 도\n",
      "구\n",
      "(T\n",
      "ools\n",
      ")\n",
      "와\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      "(\n",
      "Agents\n",
      ")\n",
      "\n",
      " \n",
      " -\n",
      " 외\n",
      "부\n",
      " API\n",
      " 호출\n",
      ",\n",
      " 계산\n",
      "기\n",
      ",\n",
      " 웹\n",
      " 검색\n",
      " 등\n",
      " 외\n",
      "부\n",
      " 기능\n",
      "에\n",
      " 접근\n",
      "하는\n",
      " Tools\n",
      " 제공\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      "가\n",
      " 도\n",
      "구\n",
      "를\n",
      " 선택\n",
      "하고\n",
      " 실행\n",
      "하도록\n",
      " 하는\n",
      " Agent\n",
      "Executor\n",
      "/\n",
      "Re\n",
      "Act\n",
      " 스타일\n",
      "의\n",
      " 패\n",
      "턴\n",
      " 지원\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 계획\n",
      "(plan\n",
      ")\n",
      "–\n",
      "행\n",
      "동\n",
      "(act\n",
      ")\n",
      " 순\n",
      "환\n",
      " 구조\n",
      "를\n",
      " 구현\n",
      "하기\n",
      " 쉬\n",
      "움\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 메\n",
      "모\n",
      "리\n",
      "(M\n",
      "emory\n",
      ")\n",
      "\n",
      " \n",
      " -\n",
      " Conversation\n",
      "Buffer\n",
      "Memory\n",
      ",\n",
      " Conversation\n",
      "Summary\n",
      "Memory\n",
      " 등\n",
      "으로\n",
      " 대\n",
      "화\n",
      " 맥\n",
      "락\n",
      "을\n",
      " 유지\n",
      "하고\n",
      " 활용\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 대\n",
      "화\n",
      " 상태\n",
      "를\n",
      " 세\n",
      "션\n",
      " 간\n",
      "에\n",
      " 공유\n",
      "하거나\n",
      " 요\n",
      "약\n",
      "해\n",
      " 저장\n",
      "하는\n",
      " 기능\n",
      " 포함\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 문\n",
      "서\n",
      " 로\n",
      "더\n",
      " 및\n",
      " 벡\n",
      "터\n",
      " 스\n",
      "토\n",
      "어\n",
      "(R\n",
      "AG\n",
      ")\n",
      "\n",
      " \n",
      " -\n",
      " 문\n",
      "서를\n",
      " 수\n",
      "집\n",
      "/\n",
      "전\n",
      "처\n",
      "리\n",
      "하는\n",
      " Document\n",
      " Load\n",
      "ers\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 임\n",
      "베\n",
      "딩\n",
      " 생성\n",
      " 및\n",
      " 벡\n",
      "터\n",
      " 검색\n",
      "을\n",
      " 위한\n",
      " Vector\n",
      " Store\n",
      "(\n",
      "예\n",
      ":\n",
      " FA\n",
      "ISS\n",
      ",\n",
      " Pine\n",
      "cone\n",
      ",\n",
      " Mil\n",
      "vus\n",
      " 등\n",
      ")\n",
      " 연\n",
      "동\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 검색\n",
      " 기반\n",
      " 응\n",
      "답\n",
      " 생성\n",
      " 등\n",
      " Retrieval\n",
      "-Aug\n",
      "mented\n",
      " Generation\n",
      " 분야\n",
      "에\n",
      " 용\n",
      "이\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 임\n",
      "베\n",
      "딩\n",
      " 및\n",
      " 검색\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 임\n",
      "베\n",
      "딩\n",
      " 모델\n",
      " 연결\n",
      " 및\n",
      " 유\n",
      "사\n",
      "도\n",
      " 기반\n",
      " 검색\n",
      " 기능\n",
      " 제공\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 출력\n",
      " 파\n",
      "서\n",
      "(Output\n",
      " Pars\n",
      "ers\n",
      ")\n",
      " 및\n",
      " 형\n",
      "식\n",
      "화\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " L\n",
      "LM\n",
      " 출력\n",
      "의\n",
      " 텍\n",
      "스트\n",
      "를\n",
      " 구조\n",
      "화\n",
      "된\n",
      " 데이터\n",
      "로\n",
      " 파\n",
      "싱\n",
      "하고\n",
      ",\n",
      " 파\n",
      "이\n",
      "프\n",
      "라인\n",
      " 다음\n",
      " 단계\n",
      "에\n",
      " 쉽게\n",
      " 전달\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 콜\n",
      "백\n",
      "/\n",
      "로\n",
      "깅\n",
      " 및\n",
      " 디\n",
      "버\n",
      "깅\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 실행\n",
      " 중\n",
      " 이벤트\n",
      "를\n",
      " 기록\n",
      "하고\n",
      " 디\n",
      "버\n",
      "깅\n",
      "을\n",
      " 용\n",
      "이\n",
      "하게\n",
      " 하는\n",
      " 콜\n",
      "백\n",
      " 시스템\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 다\n",
      "중\n",
      " 언\n",
      "어\n",
      " 지원\n",
      " 및\n",
      " 확\n",
      "장\n",
      "성\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " Python\n",
      "과\n",
      " Type\n",
      "Script\n",
      "/\n",
      "Java\n",
      "Script\n",
      " 버\n",
      "전\n",
      " 모두\n",
      "를\n",
      " 지원\n",
      "하는\n",
      " 다\n",
      "중\n",
      " 언\n",
      "어\n",
      " 프\n",
      "레\n",
      "임\n",
      "워크\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 모\n",
      "듈\n",
      "화\n",
      "된\n",
      " 컴\n",
      "포\n",
      "넌\n",
      "트를\n",
      " 직접\n",
      " 확\n",
      "장\n",
      "하거나\n",
      " 커\n",
      "스\n",
      "텀\n",
      " 컴\n",
      "포\n",
      "넌\n",
      "트를\n",
      " 추가\n",
      "하기\n",
      " 쉬\n",
      "움\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      " 생\n",
      "태\n",
      "계\n",
      " 및\n",
      " 통\n",
      "합\n",
      "성\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 다양한\n",
      " 프\n",
      "런\n",
      "트\n",
      "/\n",
      "백\n",
      "엔\n",
      "드\n",
      " 구성\n",
      " 요소\n",
      "와\n",
      "의\n",
      " 통\n",
      "합\n",
      "이\n",
      " 용\n",
      "이\n",
      "하고\n",
      ",\n",
      " 예\n",
      "제\n",
      "와\n",
      " 문\n",
      "서\n",
      "가\n",
      " 활\n",
      "발\n",
      "히\n",
      " 제공\n",
      "됨\n",
      "\n",
      "\n",
      " \n",
      " -\n",
      " 커\n",
      "뮤니\n",
      "티\n",
      " 플\n",
      "러\n",
      "그\n",
      "인\n",
      "이나\n",
      " 확\n",
      "장\n",
      "으로\n",
      " 기능\n",
      "을\n",
      " 확\n",
      "장\n",
      "하기\n",
      " 쉬\n",
      "움\n",
      "\n",
      "\n",
      "\n",
      "주\n",
      "요\n",
      " 사용\n",
      " 시\n",
      "나\n",
      "리\n",
      "오\n",
      "\n",
      "\n",
      "-\n",
      " 대\n",
      "화\n",
      "형\n",
      " 에\n",
      "이\n",
      "전\n",
      "트\n",
      " with\n",
      " 메\n",
      "모\n",
      "리\n",
      ":\n",
      " 맥\n",
      "락\n",
      "을\n",
      " 기억\n",
      "하는\n",
      " 챗\n",
      "봇\n",
      "이나\n",
      " 도\n",
      "우\n",
      "미\n",
      "\n",
      "\n",
      "-\n",
      " 문\n",
      "서\n",
      " 기반\n",
      " Q\n",
      "&A\n",
      " 및\n",
      " 지\n",
      "식\n",
      " 추\n",
      "출\n",
      ":\n",
      " 문\n",
      "서를\n",
      " 읽\n",
      "고\n",
      " 질문\n",
      "에\n",
      " 답\n",
      "하는\n",
      " 시스템\n",
      "\n",
      "\n",
      "-\n",
      " Retrieval\n",
      "-Aug\n",
      "mented\n",
      " Generation\n",
      "(R\n",
      "AG\n",
      ")\n",
      " 파\n",
      "이\n",
      "프\n",
      "라인\n",
      ":\n",
      " 외\n",
      "부\n",
      " 지\n",
      "식\n",
      " 소\n",
      "스를\n",
      " 검색\n",
      "해\n",
      " 답\n",
      "변\n",
      "에\n",
      " 활용\n",
      "\n",
      "\n",
      "-\n",
      " API\n",
      " 자동\n",
      "화\n",
      " 봇\n",
      ":\n",
      " 여러\n",
      " 외\n",
      "부\n",
      " API\n",
      "를\n",
      " 조\n",
      "합\n",
      "해\n",
      " 자동\n",
      "화\n",
      " 작업\n",
      " 수행\n",
      "\n",
      "\n",
      "\n",
      "필\n",
      "요\n",
      "에\n",
      " 따라\n",
      " Lang\n",
      "Chain\n",
      "의\n",
      " 각\n",
      " 구성\n",
      " 요소\n",
      "를\n",
      " 독\n",
      "립\n",
      "적으로\n",
      " 사용\n",
      "하거나\n",
      " 조\n",
      "합\n",
      "해\n",
      " 복\n",
      "잡\n",
      "한\n",
      " 애\n",
      "플\n",
      "리\n",
      "케\n",
      "이션\n",
      "을\n",
      " 구성\n",
      "할\n",
      " 수\n",
      " 있습니다\n",
      ".\n",
      " 원\n",
      "하\n",
      "시면\n",
      " 특정\n",
      " 사용\n",
      " 사례\n",
      "에\n",
      " 맞\n",
      "춘\n",
      " 간\n",
      "단\n",
      "한\n",
      " 구성\n",
      " 예\n",
      "시\n",
      "도\n",
      " 함께\n",
      " 설명\n",
      "해\n",
      " 드\n",
      "리\n",
      "겠습니다\n",
      ".\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스트리밍 중에 받아온 chunk 들을 저장할 리스트\n",
    "chunks = []\n",
    "\n",
    "# 전체 메시지를 누적할 변수\n",
    "full_message = None\n",
    "\n",
    "# model.stream() 은 토큰(혹은 chunk)을 스트리밍 방식으로 하나씩 생성\n",
    "for chunk in model.stream(\"LangChain의 주요 기능은 무엇인가요?\"):\n",
    "    \n",
    "    chunks.append(chunk)\n",
    "    print(chunk.text)   # 현재 chunk 의 텍스트 출력 \n",
    "    \n",
    "    # full_message 에 chunk 를 누적\n",
    "    # 첫 chunk 일 경우 full_message 가 None 이므로 그대로 저장\n",
    "    # 이후부터는 기존 full_message 에 chunk 를 더해(concat) 전체 메시지를 구성\n",
    "    full_message = chunk if full_message is None else full_message + chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2aaa89-6eed-4ed5-bf15-16d792e993b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='여러 가지 LLM 기반 애플리케이션을 쉽게 구축하도록 돕는 프레임워크가 LangChain입니다. 주요 기능을 요약하면 다음과 같습니다.\\n\\n- LLM 및 프롬프트 관리\\n  - 다양한 LLM 공급자와의 래퍼 지원(OpenAI, Cohere, HuggingFace 등)\\n  - PromptTemplate, ChatPromptTemplate 등을 이용한 재사용 가능한 프롬프트 구성\\n\\n- 체인(Chain) 기반 파이프라인\\n  - LLMChain, SimpleSequentialChain, SequentialChain 등으로 여러 LLM 호출을 순차적으로 연결\\n  - 파이프라인 형태의 로직을 손쉽게 구성하고 재사용 가능\\n\\n- 도구(Tools)와 에이전트(Agents)\\n  - 외부 API 호출, 계산기, 웹 검색 등 외부 기능에 접근하는 Tools 제공\\n  - 에이전트가 도구를 선택하고 실행하도록 하는 AgentExecutor/ReAct 스타일의 패턴 지원\\n  - 계획(plan)–행동(act) 순환 구조를 구현하기 쉬움\\n\\n- 메모리(Memory)\\n  - ConversationBufferMemory, ConversationSummaryMemory 등으로 대화 맥락을 유지하고 활용\\n  - 대화 상태를 세션 간에 공유하거나 요약해 저장하는 기능 포함\\n\\n- 문서 로더 및 벡터 스토어(RAG)\\n  - 문서를 수집/전처리하는 Document Loaders\\n  - 임베딩 생성 및 벡터 검색을 위한 Vector Store(예: FAISS, Pinecone, Milvus 등) 연동\\n  - 검색 기반 응답 생성 등 Retrieval-Augmented Generation 분야에 용이\\n\\n- 임베딩 및 검색\\n  - 임베딩 모델 연결 및 유사도 기반 검색 기능 제공\\n\\n- 출력 파서(Output Parsers) 및 형식화\\n  - LLM 출력의 텍스트를 구조화된 데이터로 파싱하고, 파이프라인 다음 단계에 쉽게 전달\\n\\n- 콜백/로깅 및 디버깅\\n  - 실행 중 이벤트를 기록하고 디버깅을 용이하게 하는 콜백 시스템\\n\\n- 다중 언어 지원 및 확장성\\n  - Python과 TypeScript/JavaScript 버전 모두를 지원하는 다중 언어 프레임워크\\n  - 모듈화된 컴포넌트를 직접 확장하거나 커스텀 컴포넌트를 추가하기 쉬움\\n\\n- 생태계 및 통합성\\n  - 다양한 프런트/백엔드 구성 요소와의 통합이 용이하고, 예제와 문서가 활발히 제공됨\\n  - 커뮤니티 플러그인이나 확장으로 기능을 확장하기 쉬움\\n\\n주요 사용 시나리오\\n- 대화형 에이전트 with 메모리: 맥락을 기억하는 챗봇이나 도우미\\n- 문서 기반 Q&A 및 지식 추출: 문서를 읽고 질문에 답하는 시스템\\n- Retrieval-Augmented Generation(RAG) 파이프라인: 외부 지식 소스를 검색해 답변에 활용\\n- API 자동화 봇: 여러 외부 API를 조합해 자동화 작업 수행\\n\\n필요에 따라 LangChain의 각 구성 요소를 독립적으로 사용하거나 조합해 복잡한 애플리케이션을 구성할 수 있습니다. 원하시면 특정 사용 사례에 맞춘 간단한 구성 예시도 함께 설명해 드리겠습니다.', additional_kwargs={}, response_metadata={'model_provider': 'openai', 'finish_reason': 'stop', 'model_name': 'gpt-5-nano-2025-08-07', 'service_tier': 'default'}, id='lc_run--c29f85fc-c621-42b1-b2ae-00b093ff0864', usage_metadata={'input_tokens': 16, 'output_tokens': 2609, 'total_tokens': 2625, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1856}}, chunk_position='last')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad55ad5-505f-4ff7-bbd9-d406c86eea55",
   "metadata": {},
   "source": [
    "### 도구 메시지 (Tool Message)\n",
    "\n",
    "도구 호출(tool calling)을 지원하는 모델의 경우,\n",
    "**AI 메시지(AIMessage)** 안에 **도구 호출 정보(tool calls)** 가 포함될 수 있습니다.\n",
    "\n",
    "**Tool Message(도구 메시지)** 는\n",
    "**단일 도구 실행의 결과(result)** 를 모델에게 다시 전달하기 위해 사용됩니다.\n",
    "\n",
    "또한, 도구는 직접 **`ToolMessage` 객체**를 생성하여\n",
    "실행 결과를 LangChain 에이전트나 모델로 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d1d23-58cc-4404-b289-5b15f25f9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# 모델이 도구 호출을 수행한 후\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",                   # 호출된 도구 이름\n",
    "        \"args\": {\"location\": \"San Francisco\"},   # 도구에 전달된 인자\n",
    "        \"id\": \"call_123\"                         # 도구 호출 ID\n",
    "    }]\n",
    ")\n",
    "\n",
    "# 도구 실행 후 결과 메시지 생성\n",
    "weather_result = \"맑음, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # 반드시 호출 ID와 일치해야 함\n",
    ")\n",
    "\n",
    "# 대화 이어가기\n",
    "messages = [\n",
    "    HumanMessage(\"샌프란시스코의 날씨는 어때?\"),\n",
    "    ai_message,     # 모델이 도구 호출을 요청한 메시지\n",
    "    tool_message,   # 도구 실행 결과를 모델에 전달\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)  # 모델이 도구 결과를 반영하여 후속 응답 생성\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630bc62-5019-4e07-af60-bc3226f468ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
