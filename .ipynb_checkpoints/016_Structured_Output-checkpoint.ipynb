{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oN_ewigHqpO0",
   "metadata": {
    "id": "oN_ewigHqpO0"
   },
   "source": [
    "# 구조화된 출력 (Structured Output)\n",
    "\n",
    "구조화된 출력은 **에이전트가 데이터를 일정하고 예측 가능한 형식으로 반환**할 수 있도록 합니다.\n",
    "즉, 사람이 읽기 위한 자연어 응답을 파싱할 필요 없이,\n",
    "**JSON 객체**, **Pydantic 모델**, 또는 **데이터클래스(dataclass)** 형태로\n",
    "애플리케이션이 **직접 사용할 수 있는 구조화된 데이터**를 받을 수 있습니다.\n",
    "\n",
    "\n",
    "LangChain의 `create_agent`는 이러한 **구조화된 출력**을 자동으로 처리합니다.\n",
    "사용자는 원하는 **출력 스키마(schema)** 를 지정하기만 하면,\n",
    "모델이 구조화된 데이터를 생성할 때 그것이 **자동으로 캡처되고, 검증(validated)** 되며,\n",
    "에이전트의 상태(`agent’s state`) 안의 `'structured_response'` 키에 포함되어 반환됩니다.\n",
    "\n",
    "```\n",
    "def create_agent(\n",
    "    ...\n",
    "    response_format: Union[\n",
    "        ToolStrategy[StructuredResponseT],\n",
    "        ProviderStrategy[StructuredResponseT],\n",
    "        type[StructuredResponseT],\n",
    "    ]\n",
    "```\n",
    "\n",
    "### Response Format\n",
    "에이전트가 구조화된 데이터를 반환하는 방식을 제어합니다:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d97476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54849d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e401c-6b29-4377-9e24-a37094155b31",
   "metadata": {},
   "source": [
    "### Pydantic을 이용하여 LLM의 구조화된 출력 유도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae80c91-e0ff-4f39-9a0b-311f68781502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"사람의 연락처 정보를 나타내는 클래스.\"\"\"\n",
    "    name: str = Field(description=\"사람의 이름\")\n",
    "    email: str = Field(description=\"사람의 이메일 주소\")\n",
    "    phone: str = Field(description=\"사람의 전화번호\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    response_format=ContactInfo  # ProviderStrategy가 자동 선택됨\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"다음 문장에서 연락처 정보를 추출해줘: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "result[\"structured_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca3f93",
   "metadata": {
    "id": "b8ca3f93"
   },
   "source": [
    "## Schema 정의와 도구 호출 \n",
    "\n",
    "LangChain에서 OpenAI의 **도구 호출(Tool Calling)** 기능을 사용하여 태깅을 수행하는 간단한 예제를 살펴보겠습니다.  \n",
    "\n",
    "- OpenAI 모델에서 지원하는 `with_structured_output` 메서드를 사용할 것입니다.  \n",
    "\n",
    "스키마에 몇 가지 속성과 예상 유형을 추가하여 Pydantic 모델을 지정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d38db89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000022F5C52B4D0>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Classification', 'description': '', 'parameters': {'properties': {'sentiment': {'description': '텍스트의 감정', 'type': 'string'}, 'agressiveness': {'description': '텍스트가 1~10점 척도로 얼마나 공격적인지를 나타냅니다.', 'type': 'integer'}}, 'required': ['sentiment', 'agressiveness'], 'type': 'object'}}}], 'ls_structured_output_format': {'kwargs': {'method': 'function_calling'}, 'schema': {'type': 'function', 'function': {'name': 'Classification', 'description': '', 'parameters': {'properties': {'sentiment': {'description': '텍스트의 감정', 'type': 'string'}, 'agressiveness': {'description': '텍스트가 1~10점 척도로 얼마나 공격적인지를 나타냅니다.', 'type': 'integer'}}, 'required': ['sentiment', 'agressiveness'], 'type': 'object'}}}}, 'tool_choice': 'Classification'}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Classification'>])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "# 주어진 텍스트에서 필요한 정보를 추출하도록 지침 제공\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "다음 글에서 원하는 정보를 추출하세요.\n",
    "'Classification' 함수에 언급된 속성만 추출하세요.\n",
    "\n",
    "글:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Pydantic 데이터 모델을 이용하여 텍스트에서 추출할 속성 정의\n",
    "# 감정의 종류와 값의 범위를 자율 지정\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"텍스트의 감정\")\n",
    "    agressiveness: int = Field(\n",
    "        description=\"텍스트가 1~10점 척도로 얼마나 공격적인지를 나타냅니다.\"\n",
    "    )\n",
    "\n",
    "# Structured Output(구조화된 출력) 생성\n",
    "llm = model.with_structured_output(Classification)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c238a91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='긍정', agressiveness=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"너를 만나게 되어 정말 기뻐! 우리는 아주 좋은 친구가 될 것 같아!\"\n",
    "\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cf30d",
   "metadata": {
    "id": "ff3cf30d"
   },
   "source": [
    "dictionary 출력을 원하면 `.model_dump()`를 호출하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b65446f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': '긍정', 'agressiveness': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921bb53",
   "metadata": {
    "id": "d921bb53"
   },
   "source": [
    "예제에서 볼 수 있듯이, 모델은 우리가 원하는 바를 정확하게 해석합니다.  \n",
    "\n",
    "다음 섹션에서는 이러한 결과를 어떻게 제어할 수 있는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb2f83",
   "metadata": {
    "id": "bebb2f83"
   },
   "source": [
    "## **더 세밀한 출력 제어**\n",
    "\n",
    "**스키마(schema)** 를 더 자세히 정의하면 모델의 출력을 더 세밀하게 제어할 수 있습니다.  \n",
    "\n",
    "구체적으로 다음을 정의할 수 있습니다:  \n",
    "\n",
    "- **각 속성의 가능한 값**  \n",
    "- **속성을 모델이 정확하게 이해할 수 있도록 설명 추가**  \n",
    "- **반드시 반환해야 할 필수 속성**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef0b9a",
   "metadata": {
    "id": "69ef0b9a"
   },
   "source": [
    "이전에 언급한 각 요소를 제어하기 위해 **Enums**를 사용하여 우리의 **Pydantic 모델**을 다시 선언해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11220ae7-d68c-45a2-891d-126b44375c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be76084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class Classification_2(BaseModel):\n",
    "    sentiment: Literal[\"행복하다\", \"화난다\", \"슬프다\"]\n",
    "    aggressiveness: Literal[1, 2, 3, 4, 5] = Field(\n",
    "        ...,\n",
    "        description=\"문장이 얼마나 공격적인지를 나타내며 숫자가 높을수록 더 공격적입니다.\"\n",
    "    )\n",
    "\n",
    "llm = model.with_structured_output(Classification_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded2332",
   "metadata": {
    "id": "5ded2332"
   },
   "source": [
    "이제 답변은 우리가 예상하는 방식으로 제한될 것입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd707ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': '화난다', 'aggressiveness': 5}\n",
      "{'sentiment': '슬프다', 'aggressiveness': 1}\n",
      "{'sentiment': '행복하다', 'aggressiveness': 1}\n"
     ]
    }
   ],
   "source": [
    "inps = [\"너를 만나면 죽여 버릭거야! 우리는 영원히 친구가 될 수 없어!\",\n",
    "        \"너를 보면 눈물이 나!\",\n",
    "        \"여기 날씨는 괜찮아요, 코트 하나 없이도 밖에 나갈 수 있어요\"]\n",
    "\n",
    "for inp in inps:\n",
    "    prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87386396-9042-49b5-98c8-21bbd1532064",
   "metadata": {},
   "source": [
    "# 구조화된 출력을 활용한 콘텐츠 심사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba29fabf-5747-4b5a-b183-8c1fcebaacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_violating': True, 'category': <Category.self_harm: '자해'>, 'explanation_if_violating': \"사용자가 '삶을 포기하고 싶어'라고 명백한 자해·자살 의향을 표현하고 있으므로 자해 관련 금지 지침에 해당합니다. 이 입력은 자해·자살을 암시하거나 권장하는 내용으로 분류됩니다.\"}\n",
      "\n",
      "{'is_violating': False, 'category': None, 'explanation_if_violating': None}\n",
      "\n",
      "{'is_violating': True, 'category': <Category.violence: '폭력'>, 'explanation_if_violating': '해당 문장은 특정인에게 심각한 신체적 피해를 가하겠다는 직접적인 폭력적 위협입니다. 위협적·폭력적 표현은 유해한 콘텐츠로 분류되어 허용되지 않습니다.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Category(str, Enum):\n",
    "    violence = \"폭력\"\n",
    "    sexual = \"성적인내용\"\n",
    "    self_harm = \"자해\"\n",
    "\n",
    "class ContentCompliance(BaseModel):\n",
    "    is_violating: bool\n",
    "    category: Optional[Category]\n",
    "    explanation_if_violating: Optional[str]\n",
    "\n",
    "llm = model.with_structured_output(ContentCompliance)\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "사용자 입력이 특정 지침을 위반하는지 판단하고 'ContentCompliance' 형식에 맞추어 출력하세요.\n",
    "한국어로 출력하세요.\n",
    "\n",
    "글:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "inps = [\"요즘 너무 힘들고 삶을 포기하고 싶어.\",\n",
    "        \"이 사진은 성적으로 노골적인 내용을 포함하고 있어.\",\n",
    "        \"니 대가리를 박살낼거야\"]\n",
    "\n",
    "for inp in inps:\n",
    "    prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response.model_dump())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e905af8-6445-4454-9649-5048ae5354f9",
   "metadata": {},
   "source": [
    "# 실습 : 구조화된 출력 코드 작성\n",
    "\n",
    "### 문제 1: 캘린더 이벤트 추출 (기초)\n",
    "\n",
    "아래 문장에서 **이름**, **날짜**, **참석자** 정보를 추출하도록 `CalendarEvent` 클래스를 정의하고, .\n",
    "\n",
    "```text\n",
    "\"민수, 유리, 그리고 지민은 다음 주 화요일에 회사 워크숍에 참석합니다.\"\n",
    "```\n",
    "\n",
    "<details>\n",
    "<summary>힌트</summary>\n",
    "\n",
    "```\n",
    "class CalendarEvent(BaseModel):\n",
    "    이름: str\n",
    "    날자: str\n",
    "    참석자: list[str]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dd083-07ce-4d1a-95eb-0180c45cca42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
