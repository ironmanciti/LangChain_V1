{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9316da0d",
   "metadata": {
    "editable": true,
    "id": "9316da0d",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **챗 모델과 Message를 사용해 간단한 LLM 애플리케이션 구축하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "I1APsrLauEiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1APsrLauEiT",
    "outputId": "07352eb4-b720-42c9-cc5d-7778166cb1fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e1b785-ee30-49d7-8b75-a6f75d26c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5558ca9",
   "metadata": {
    "id": "e5558ca9"
   },
   "source": [
    "## 언어 모델 사용하기\n",
    "\n",
    "LangChain은 다양한 언어 모델을 지원하며, 이들을 서로 교체하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b41234",
   "metadata": {
    "id": "e4b41234"
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-5-nano\", model_provider=\"openai\")\n",
    "# model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5642ff",
   "metadata": {
    "id": "ca5642ff"
   },
   "source": [
    "ChatModels은 LangChain Runnables의 인스턴스로, 표준화된 인터페이스를 통해 상호작용할 수 있습니다. 모델을 간단히 호출하려면 `.invoke` 메서드에 Messages 목록을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc68f2-e940-41af-b949-9bec65100923",
   "metadata": {},
   "source": [
    "## 메시지 (Messages)\n",
    "\n",
    "메시지(Messages) 는 LangChain에서 모델이 사용하는 컨텍스트의 기본 단위입니다.\n",
    "이들은 모델의 입력(input) 과 출력(output) 을 나타내며, LLM과의 상호작용에서 대화의 상태(state)를 표현하는 데 필요한 콘텐츠(content) 와 메타데이터(metadata) 를 함께 포함합니다.\n",
    "\n",
    "메시지는 다음 요소들로 구성됩니다:\n",
    "\n",
    "- Role (역할)\n",
    "→ 메시지의 유형을 식별합니다. 예: system, user, assistant 등  \n",
    "- Content (내용)\n",
    "→ 메시지의 실제 내용으로, 텍스트뿐만 아니라 이미지, 오디오, 문서 등 다양한 형식을 포함할 수 있습니다.  \n",
    "- Metadata (메타데이터)\n",
    "→ 선택적(optional) 필드로, 응답 정보(response info), 메시지 ID, 토큰 사용량(token usage) 등 부가 정보를 담습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2481f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b2481f0",
    "outputId": "4323da7b-9ebf-4ed3-f3b1-5cf182dafd16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain이 무엇인가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 272, 'prompt_tokens': 40, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CWYYsEATakrGHWtXbtNwPZVMjrlXm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--cb4b077d-5b7c-427a-a184-1948751bc42d-0', usage_metadata={'input_tokens': 40, 'output_tokens': 272, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 메시지 목록을 생성\n",
    "messages = [\n",
    "    # 시스템 메시지: 모델에게 수행할 작업이나 역할을 지시합니다.\n",
    "    SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "    # 사용자 메시지: 사용자가 모델에 보낼 실제 입력 내용입니다.\n",
    "    HumanMessage(\"What is LangChain?\"),\n",
    "]\n",
    "\n",
    "answer = model.invoke(messages)  # `invoke` 메서드를 사용해 모델을 호출합니다.\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "CGRBL2IrZcsP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGRBL2IrZcsP",
    "outputId": "2d3464d8-e61c-4972-a3d2-c3de59493a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain이 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cbd960-d92a-42ba-89c5-a4a664bc7b88",
   "metadata": {},
   "source": [
    "### 텍스트 프롬프트 (Text prompts)\n",
    "\n",
    "**텍스트 프롬프트(Text prompts)** 는 단순한 **문자열(string)** 형태로 제공됩니다.  \n",
    "대화 기록(conversation history)을 유지할 필요가 없는 **단순한 생성 작업**(예: 요약, 문장 생성, 번역 등)에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1034d669-aa6e-4980-9ada-c4f97e63e5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "데이터 바다 건너온 지혜,\n",
      "언어로 세상을 엮네.\n",
      "묻는 자에게 답을 주고,\n",
      "새로운 이야기를 펼쳐.\n",
      "코드 속에 피어난 생각의 꽃.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"LLM 에 관한 시를 5줄 이내로 지어주세요.\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ae698-b258-41f2-bff3-591e871781ae",
   "metadata": {},
   "source": [
    "### 딕셔너리 형식 (Dictionary format)\n",
    "\n",
    "OpenAI의 **Chat Completions 포맷**을 사용해 메시지를 **딕셔너리 형태로 직접 지정**할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b65209b-6307-414f-a612-d8cfa114e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "랭체인이 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 형식\n",
    "answer = model.invoke([\n",
    "    {\"role\": \"system\", \"content\": \"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is LangChain?\"},\n",
    "])\n",
    "answer.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101b1e5-00e3-44cd-99e8-622c9076964f",
   "metadata": {},
   "source": [
    "--------------\n",
    "## 메시지 유형 (Message types)\n",
    "\n",
    "* **System message (시스템 메시지)**\n",
    "  → 모델이 어떻게 행동해야 하는지 지시하고, 상호작용의 **맥락(context)** 을 제공합니다.  \n",
    "* **Human message (사용자 메시지)**\n",
    "  → 사용자의 입력을 나타내며, 모델과의 **대화(interaction)** 를 구성합니다.  \n",
    "* **AI message (AI 메시지)**\n",
    "  → 모델이 생성한 응답으로, **텍스트 내용(text content)** 뿐 아니라\n",
    "  **도구 호출(tool calls)** 및 **메타데이터(metadata)** 를 포함할 수 있습니다.  \n",
    "* **Tool message (도구 메시지)**\n",
    "  → 모델이 호출한 **도구의 실행 결과(outputs)** 를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b244e713-c236-43e7-b2d6-efa2b9764527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Python에서는 Flask나 Django REST Framework(DRF) 같은 웹 프레임워크를 활용합니다.\n",
      "리소스 기반의 URL을 설계하고, GET, POST, PUT, DELETE 등 HTTP 메서드를 적절히 매핑하세요.\n",
      "데이터는 주로 JSON 형식으로 직렬화하여 클라이언트와 주고받습니다.\n",
      "프레임워크의 라우팅, 뷰, 모델 기능을 사용하여 API 엔드포인트를 구현합니다.\n",
      "복잡한 API에는 DRF와 같은 전문 라이브러리 사용을 권장합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import SystemMessage, HumanMessage\n",
    "\n",
    "system_msg = SystemMessage(\"\"\"\n",
    "당신은 웹 프레임워크에 전문성을 가진 시니어 Python 개발자입니다.\n",
    "설명은 간결하게 5줄 이내로 설명하세요.\n",
    "\"\"\")\n",
    "\n",
    "messages = [\n",
    "    system_msg,\n",
    "    HumanMessage(\"REST API를 어떻게 만들 수 있나요?\")\n",
    "]\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd416a6-4bb9-4c1d-a43a-d52c5f8a4b5d",
   "metadata": {},
   "source": [
    "### AI 메시지 (AI Message)\n",
    "\n",
    "**AIMessage** 는 **모델 호출(model invocation)** 의 **출력 결과**를 나타냅니다.\n",
    "이 메시지에는 다음과 같은 요소들을 포함할 수 있습니다:\n",
    "\n",
    "* **멀티모달 데이터 (Multimodal data)** — 텍스트뿐만 아니라 이미지, 오디오 등의 출력\n",
    "* **도구 호출 (Tool calls)** — 모델이 외부 도구를 실행한 기록\n",
    "* **제공자별 메타데이터 (Provider-specific metadata)** — 모델 제공자(OpenAI, Anthropic 등)에 따라 추가로 제공되는 정보\n",
    "\n",
    "이러한 메타데이터는 나중에 접근하거나 분석할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45de4fe-764a-4da1-90bf-c5ecf06da539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인간의 지능을 모방하여 학습하고 추론하며 문제를 해결하는 기술.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--7813ec8f-0a37-4c09-ac0d-9094ab78f6ec-0', usage_metadata={'input_tokens': 11, 'output_tokens': 1421, 'total_tokens': 1432, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1402}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"AI에 대해서 한줄로 설명해줘.\")\n",
    "print(type(response))  \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb097b8e-c693-4957-a33f-db56b6b995ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 + 2는 **4**입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# AI 메시지를 수동으로 생성 (예: 대화 기록에 추가하기 위해)\n",
    "ai_msg = AIMessage(\"그 질문에 기꺼이 도움을 드리겠습니다!\")\n",
    "\n",
    "# 대화 기록에 추가\n",
    "messages = [\n",
    "    SystemMessage(\"당신은 도움이 되는 어시스턴트입니다.\"),\n",
    "    HumanMessage(\"저를 도와주실 수 있나요?\"),\n",
    "    ai_msg,  # 모델이 이전에 응답한 것처럼 삽입\n",
    "    HumanMessage(\"좋아요! 그럼 2 + 2는 얼마인가요?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b9ac0-25ab-4d44-88a8-111814b0e719",
   "metadata": {},
   "source": [
    "### 도구 호출 (Tool calls)\n",
    "\n",
    "모델이 **도구 호출(tool call)** 을 수행할 때, 그 호출 정보는 **AIMessage** 객체 내부에 포함됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31ea453a-724a-434a-b3a4-caabc28f04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구 이름: get_weather\n",
      "인자값(Args): {'location': 'Paris'}\n",
      "ID: e6ce9cfc-af97-4574-86fa-ad423cb163f2\n"
     ]
    }
   ],
   "source": [
    "# 도구 정의\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"특정 위치의 날씨를 가져옵니다.\"\"\"\n",
    "    ...\n",
    "\n",
    "# 모델에 도구 바인딩\n",
    "model_with_tools = model.bind_tools([get_weather])\n",
    "\n",
    "# 모델 호출\n",
    "response = model_with_tools.invoke(\"파리의 날씨는 어때?\")\n",
    "\n",
    "# 모델이 호출한 도구 정보 출력\n",
    "for tool_call in response.tool_calls:\n",
    "    print(f\"도구 이름: {tool_call['name']}\")\n",
    "    print(f\"인자값(Args): {tool_call['args']}\")\n",
    "    print(f\"ID: {tool_call['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a4174-9202-43d4-b458-55c5f67463ed",
   "metadata": {},
   "source": [
    "### 토큰 사용량 (Token usage)\n",
    "\n",
    "**AIMessage** 객체는 `usage_metadata` 필드에\n",
    "**토큰 사용량(token counts)** 및 기타 **사용 관련 메타데이터(metadata)** 를 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed023e1c-0c69-42d8-99d9-2fb0ab1ade9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 3,\n",
       " 'output_tokens': 35,\n",
       " 'total_tokens': 38,\n",
       " 'input_token_details': {'cache_read': 0},\n",
       " 'output_token_details': {'reasoning': 25}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(\"Hello!\")\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf8e88-819c-445f-ae28-92f05e549cb4",
   "metadata": {},
   "source": [
    "### batch interface 이용 여러개의 메시지 일괄 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f26b9c15-aefd-4908-a3c8-0d558f39b2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='LangChain은 무엇인가요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--bc578f65-9ff5-4cf3-b691-d80a4d0ba33c-0', usage_metadata={'input_tokens': 27, 'output_tokens': 142, 'total_tokens': 169, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 135}}),\n",
       " AIMessage(content='LangChain은 어떻게 작동하나요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--eda465e1-e490-44ca-907a-6f6cdfe39f05-0', usage_metadata={'input_tokens': 28, 'output_tokens': 8, 'total_tokens': 36, 'input_token_details': {'cache_read': 0}}),\n",
       " AIMessage(content='LangChain의 주요 기능은 무엇인가요?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--de882d0f-b9ca-409d-a3b5-7468d09f9141-0', usage_metadata={'input_tokens': 31, 'output_tokens': 41, 'total_tokens': 72, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 31}})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메시지 목록을 생성\n",
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What is LangChain?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"How does LangChain work?\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\"다음을 영어에서 한국어로 번역하세요. 상세한 설명 말고 단순히 번역만 하세요.\"),\n",
    "        HumanMessage(\"What are the key features of LangChain?\")\n",
    "    ]\n",
    "]\n",
    "\n",
    "# `model.batch()`을 사용하여 여러 개의 메시지를 한 번에 처리\n",
    "# LangChain은 각 입력을 독립된 invoke() 호출처럼 처리\n",
    "answers = model.batch(batch_messages)\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018da27f-d225-4f9d-aa94-6d6cabce66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번역 1: LangChain은 무엇인가요?\n",
      "번역 2: LangChain은 어떻게 작동하나요?\n",
      "번역 3: LangChain의 주요 기능은 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "for idx, ans in enumerate(answers):\n",
    "    print(f\"번역 {idx + 1}: {ans.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c76047bf-3c63-4460-9f5d-f991aa6472a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 오픈소스 프레임워크입니다. LLM의 잠재력을 최대한 발휘하고, 복잡한 워크플로우\n",
      "를 쉽게 구축할 수 있도록 다양한 모듈과 기능을 제공합니다.\n",
      "\n",
      "LangChain의 주요 기능은 다음과 같습니다:\n",
      "\n",
      "1.  **LLM 모델 통합 (LLM Integrations):**\n",
      "    *   OpenAI, Hugging\n",
      " Face, Anthropic, Google Gemini 등 다양한 LLM 제공업체 및 로컬에서 호스팅되는 모델과의 쉬운 연동을 지원합니다.\n",
      "    *   개발자는 특정 LLM에 종속되지 않고, 필요에 따라 모델\n",
      "을 쉽게 교체할 수 있습니다.\n",
      "\n",
      "2.  **프롬프트 관리 (Prompt Management):**\n",
      "    *   프롬프트 템플릿: LLM에 전달할 프롬프트를 동적으로 생성하고 관리\n",
      "할 수 있는 템플릿 기능을 제공합니다.\n",
      "    *   프롬프트 엔지니어링: Few-shot 프롬프팅, 출력 파서 등을 통해 LLM의 입력 및 출력을 효율적으로 관리하고 최\n",
      "적화합니다.\n",
      "\n",
      "3.  **체인 (Chains):**\n",
      "    *   여러 구성 요소를 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 합니다.\n",
      "    *   예를 들어, 사용자 입력\n",
      " -> LLM 호출 -> 결과 파싱 -> 다음 LLM 호출 등으로 이어지는 워크플로우를 만들 수 있습니다.\n",
      "    *   다양한 미리 정의된 체인(예: `LLMChain`, `SimpleSequential\n",
      "Chain`)을 제공하며, 사용자가 직접 커스텀 체인을 구성할 수도 있습니다.\n",
      "\n",
      "4.  **에이전트 (Agents):**\n",
      "    *   LLM이 스스로 판단하여 어떤 도구를 사용하고 어떤 작업을 수행할\n",
      "지 결정하도록 돕습니다.\n",
      "    *   LLM에게 추론 능력과 행동 능력을 부여하여 동적으로 문제를 해결하게 합니다. 예를 들어, \"오늘 날씨는 어때? 그리고 내일 주식 시장은 어떻게\n",
      " 될 것 같아?\" 같은 복합적인 질문에 대해 LLM이 적절한 도구(날씨 API, 주식 예측 모델)를 선택하여 사용하게 할 수 있습니다.\n",
      "\n",
      "5.  **도구 (Tools\n",
      "):**\n",
      "    *   에이전트가 사용할 수 있는 외부 기능들을 의미합니다.\n",
      "    *   웹 검색(Google Search, DuckDuckGo), 계산기, API 호출, 데이터베이스 조회, 파일 시스템 접근 등 다양한 도구를\n",
      " LLM에 연결하여 LLM의 한계를 보완하고 외부 세계와 상호작용하게 합니다.\n",
      "\n",
      "6.  **메모리 (Memory):**\n",
      "    *   대화 기록이나 이전 상호작용의 맥락\n",
      "을 저장하여 LLM이 장기적인 대화나 복잡한 시나리오를 처리할 수 있도록 돕습니다.\n",
      "    *   `ConversationBufferMemory`, `ConversationSummaryMemory` 등 다양한 메모리 유형을 제공합니다.\n",
      "\n",
      "\n",
      "7.  **데이터 검색 및 관리 (Retrieval):**\n",
      "    *   외부 데이터 소스(문서, 데이터베이스, 웹페이지 등)에서 관련 정보를 검색하고 LLM에 제공하는 기능을 담당합니다.\n",
      "\n",
      "    *   **RAG (Retrieval Augmented Generation)** 패턴을 구현하여 LLM의 답변 정확도와 최신 정보를 반영하는 데 필수적입니다.\n",
      "    *   **문서 로더 (Document Loaders):** PDF\n",
      ", CSV, 웹페이지 등 다양한 형식의 문서를 불러옵니다.\n",
      "    *   **텍스트 분할기 (Text Splitters):** 불러온 문서를 LLM이 처리하기 적합한 크기로 분할합니다.\n",
      "\n",
      "    *   **벡터 스토어 (Vector Stores):** 분할된 텍스트를 임베딩하여 벡터 데이터베이스에 저장하고, 유사도 검색을 통해 관련성 높은 정보를 빠르게 찾아냅니다. (예: Chroma,\n",
      " Pinecone, FAISS)\n",
      "\n",
      "8.  **LangChain 표현 언어 (LCEL - LangChain Expression Language):**\n",
      "    *   LangChain의 핵심적인 기능 중 하나로, 복잡한 체인을 선언적이고 파\n",
      "이프라인 방식으로 쉽게 구축하고 조합할 수 있게 하는 기능입니다.\n",
      "    *   모듈성을 높이고, 스트리밍 및 비동기 처리를 지원하여 체인의 성능과 유연성을 향상시킵니다.\n",
      "\n",
      "\n",
      "결론적으로 LangChain은 LLM 기반 애플리케이션 개발의 복잡성을 줄이고, 모듈화된 접근 방식을 통해 개발자가 다양한 LLM 기능을 쉽게 조합하고 확장할 수 있도록 돕는 강력한 도구\n",
      "입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "full_message = None\n",
    "for chunk in model.stream(\"LangChain의 주요 기능은 무엇인가요?\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.text)\n",
    "    full_message = chunk if full_message is None else full_message + chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b2aaa89-6eed-4ed5-bf15-16d792e993b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발을 위한 오픈소스 프레임워크입니다. LLM의 잠재력을 최대한 발휘하고, 복잡한 워크플로우를 쉽게 구축할 수 있도록 다양한 모듈과 기능을 제공합니다.\\n\\nLangChain의 주요 기능은 다음과 같습니다:\\n\\n1.  **LLM 모델 통합 (LLM Integrations):**\\n    *   OpenAI, Hugging Face, Anthropic, Google Gemini 등 다양한 LLM 제공업체 및 로컬에서 호스팅되는 모델과의 쉬운 연동을 지원합니다.\\n    *   개발자는 특정 LLM에 종속되지 않고, 필요에 따라 모델을 쉽게 교체할 수 있습니다.\\n\\n2.  **프롬프트 관리 (Prompt Management):**\\n    *   프롬프트 템플릿: LLM에 전달할 프롬프트를 동적으로 생성하고 관리할 수 있는 템플릿 기능을 제공합니다.\\n    *   프롬프트 엔지니어링: Few-shot 프롬프팅, 출력 파서 등을 통해 LLM의 입력 및 출력을 효율적으로 관리하고 최적화합니다.\\n\\n3.  **체인 (Chains):**\\n    *   여러 구성 요소를 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 합니다.\\n    *   예를 들어, 사용자 입력 -> LLM 호출 -> 결과 파싱 -> 다음 LLM 호출 등으로 이어지는 워크플로우를 만들 수 있습니다.\\n    *   다양한 미리 정의된 체인(예: `LLMChain`, `SimpleSequentialChain`)을 제공하며, 사용자가 직접 커스텀 체인을 구성할 수도 있습니다.\\n\\n4.  **에이전트 (Agents):**\\n    *   LLM이 스스로 판단하여 어떤 도구를 사용하고 어떤 작업을 수행할지 결정하도록 돕습니다.\\n    *   LLM에게 추론 능력과 행동 능력을 부여하여 동적으로 문제를 해결하게 합니다. 예를 들어, \"오늘 날씨는 어때? 그리고 내일 주식 시장은 어떻게 될 것 같아?\" 같은 복합적인 질문에 대해 LLM이 적절한 도구(날씨 API, 주식 예측 모델)를 선택하여 사용하게 할 수 있습니다.\\n\\n5.  **도구 (Tools):**\\n    *   에이전트가 사용할 수 있는 외부 기능들을 의미합니다.\\n    *   웹 검색(Google Search, DuckDuckGo), 계산기, API 호출, 데이터베이스 조회, 파일 시스템 접근 등 다양한 도구를 LLM에 연결하여 LLM의 한계를 보완하고 외부 세계와 상호작용하게 합니다.\\n\\n6.  **메모리 (Memory):**\\n    *   대화 기록이나 이전 상호작용의 맥락을 저장하여 LLM이 장기적인 대화나 복잡한 시나리오를 처리할 수 있도록 돕습니다.\\n    *   `ConversationBufferMemory`, `ConversationSummaryMemory` 등 다양한 메모리 유형을 제공합니다.\\n\\n7.  **데이터 검색 및 관리 (Retrieval):**\\n    *   외부 데이터 소스(문서, 데이터베이스, 웹페이지 등)에서 관련 정보를 검색하고 LLM에 제공하는 기능을 담당합니다.\\n    *   **RAG (Retrieval Augmented Generation)** 패턴을 구현하여 LLM의 답변 정확도와 최신 정보를 반영하는 데 필수적입니다.\\n    *   **문서 로더 (Document Loaders):** PDF, CSV, 웹페이지 등 다양한 형식의 문서를 불러옵니다.\\n    *   **텍스트 분할기 (Text Splitters):** 불러온 문서를 LLM이 처리하기 적합한 크기로 분할합니다.\\n    *   **벡터 스토어 (Vector Stores):** 분할된 텍스트를 임베딩하여 벡터 데이터베이스에 저장하고, 유사도 검색을 통해 관련성 높은 정보를 빠르게 찾아냅니다. (예: Chroma, Pinecone, FAISS)\\n\\n8.  **LangChain 표현 언어 (LCEL - LangChain Expression Language):**\\n    *   LangChain의 핵심적인 기능 중 하나로, 복잡한 체인을 선언적이고 파이프라인 방식으로 쉽게 구축하고 조합할 수 있게 하는 기능입니다.\\n    *   모듈성을 높이고, 스트리밍 및 비동기 처리를 지원하여 체인의 성능과 유연성을 향상시킵니다.\\n\\n결론적으로 LangChain은 LLM 기반 애플리케이션 개발의 복잡성을 줄이고, 모듈화된 접근 방식을 통해 개발자가 다양한 LLM 기능을 쉽게 조합하고 확장할 수 있도록 돕는 강력한 도구입니다.', additional_kwargs={}, response_metadata={'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai', 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash'}, id='lc_run--2dcd355f-05e8-4931-8b05-855a6dc16cc2', usage_metadata={'input_tokens': 11, 'output_tokens': 2497, 'total_tokens': 2508, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1515}}, chunk_position='last')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad55ad5-505f-4ff7-bbd9-d406c86eea55",
   "metadata": {},
   "source": [
    "### 도구 메시지 (Tool Message)\n",
    "\n",
    "도구 호출(tool calling)을 지원하는 모델의 경우,\n",
    "**AI 메시지(AIMessage)** 안에 **도구 호출 정보(tool calls)** 가 포함될 수 있습니다.\n",
    "\n",
    "**Tool Message(도구 메시지)** 는\n",
    "**단일 도구 실행의 결과(result)** 를 모델에게 다시 전달하기 위해 사용됩니다.\n",
    "\n",
    "또한, 도구는 직접 **`ToolMessage` 객체**를 생성하여\n",
    "실행 결과를 LangChain 에이전트나 모델로 반환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856d1d23-58cc-4404-b289-5b15f25f9322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "샌프란시스코의 날씨는 **맑고 72°F (약 22°C)**입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# 모델이 도구 호출을 수행한 후\n",
    "ai_message = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\": \"get_weather\",                   # 호출된 도구 이름\n",
    "        \"args\": {\"location\": \"San Francisco\"},   # 도구에 전달된 인자\n",
    "        \"id\": \"call_123\"                         # 도구 호출 ID\n",
    "    }]\n",
    ")\n",
    "\n",
    "# 도구 실행 후 결과 메시지 생성\n",
    "weather_result = \"맑음, 72°F\"\n",
    "tool_message = ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"  # 반드시 호출 ID와 일치해야 함\n",
    ")\n",
    "\n",
    "# 대화 이어가기\n",
    "messages = [\n",
    "    HumanMessage(\"샌프란시스코의 날씨는 어때?\"),\n",
    "    ai_message,     # 모델이 도구 호출을 요청한 메시지\n",
    "    tool_message,   # 도구 실행 결과를 모델에 전달\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)  # 모델이 도구 결과를 반영하여 후속 응답 생성\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630bc62-5019-4e07-af60-bc3226f468ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
